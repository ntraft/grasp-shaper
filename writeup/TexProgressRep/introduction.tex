\renewcommand{\thesection}{\Roman{section}}
\thispagestyle{empty}
\section{Introduction}
\quad When humans perform simple grasping task in every day life, they depend on a combination of their visual system as well as their sensorimotor memory. Hereby, the human hand relies on about 17000 mechanoreceptive tactile units \cite{SkinTouch} embedded in the hairless skin of the palm that are able to give feedback in response to e.g. touch, pressure or vibrations, constantly adapting fingertip forces and grasping strength. Lifting up an object, such as a cup or a pen, is consequently followed by a cascade of sensory signal generation and processing \cite{TortaGerardJ.2011}. 

In humans, visual information of the objects properties during grasping is important, however not essential  \cite{VisualSensory}. Consequently, a lot of research effort has been put into tactile-driven approaches for robotic grasp control \cite{LeeNicholls} \cite{Yousef1}. The main challenge remains yet to find a dexterous robotic grasping technique that can cope with the wide range of different grasping contexts. In other words, to mimic natural human grasping behavior as accurate as possible. 

Conventionally, there are two approaches to develop grasping strategies and algorithms. While the first one uses geometric object models, i.e. calculates a geometry-based object specific optimal hand posture, the second approach solely depends on tactile feedback upon contact with the object being grasped. Both approaches have the drawback that each grasp will be performed independently of the previous grasp experience. In contrast to this, humans use previous grasping information to \emph{preshape} their grasp. (The simple example of a person lying in bed at night and reaching for a glass of water as opposed to a phone or a book illustrates this.) Accordingly, more recent ideas integrate some kind of \emph{grasp experience} into the planning of the subsequent grasp \cite{Steffen}\cite{Pastor}. 

The main idea of grasp adaptation is to use previously acquired grasping knowledge to improve future grasping strategies. This can, for example, be achieved by storing hand postures of successful grasping trials in a database. Upon initial finger contact with the object, a suitable hand posture can then be chosen from the database. Consequently, the grasp is more likely to succeed \cite{Steffen}.

In our approach we want to make use of the tactile feedback of the Barrett hand. As we expect the tactile feedback to be distinct for individual shapes, we plan to implement an adaptation of the hand posture for repetitive grasping based on the respective previous task. To put it in simpler words, we want to see the hand fail to grasp on an initial trial, however, teach it to learn from its failure.

